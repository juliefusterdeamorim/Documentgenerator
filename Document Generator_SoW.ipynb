{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUnemGqIXp4UOWbS1YND0b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juliefusterdeamorim/Documentgenerator/blob/main/Document%20Generator_SoW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "csvzwlzLGyI3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2642d5b3-12f1-4367-9fae-d2416005cd42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit langchain python-docx openai==0.28.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import io\n",
        "from docx import Document\n",
        "from docx.shared import Pt\n",
        "import streamlit as st\n",
        "#from apikey import apikey\n",
        "import langchain\n",
        "from langchain.llms import openai\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain, SequentialChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Set up the environment variable for OpenAI API key\n",
        "os.environ['OPENAI_API_KEY'] = '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'\n",
        "\n",
        "# Initialize Streamlit app\n",
        "st.title(\"PMO Document Generator\")\n",
        "\n",
        "# User input\n",
        "prompt = st.text_input('Enter prompt for documentation here')\n",
        "\n",
        "# Function to save response to Word document\n",
        "def save_to_word(doc_title, doc_content):\n",
        "    # Create a new Document\n",
        "    doc = Document()\n",
        "    doc.add_heading(doc_title, 0)\n",
        "\n",
        "    # Add the content to the Document\n",
        "    p = doc.add_paragraph('')\n",
        "    runner = p.add_run(doc_content)\n",
        "    runner.font.size = Pt(12)  # Optionally set the font size\n",
        "\n",
        "    # Save the document to an in-memory buffer\n",
        "    buffer = io.BytesIO()\n",
        "    doc.save(buffer)\n",
        "    buffer.seek(0)\n",
        "\n",
        "    # Return the buffer\n",
        "    return buffer\n",
        "\n",
        "# Prompt templates\n",
        "#prompt tempalate\n",
        "title_template = PromptTemplate(\n",
        "    input_variables= ['topic'],\n",
        "    template= \"\"\"Please generate a comprehensive Project Initiation Document for the topic {topic}.\n",
        "    \\\\This document should thoroughly delineate the scope of the project and provide sample text for each of the listed sections.\n",
        "    \\\\The structure should follow standard project initiation documentation format and include the following sections: Introduction: Briefly introduce the topic and its significance.\n",
        "    \\\\SOW Prepared by: (Input name here)\n",
        "    \\\\Client Name: (Input Client's name here)\n",
        "    \\\\Project Scope: Define the boundaries of the project, including what is within and outside the scope.\n",
        "    \\\\Objectives: State the primary goals and objectives the project aims to achieve.\n",
        "    \\\\Background: Briefly describe the project and why it is being undertaken.\n",
        "    \\\\Project Objectives: State the main goals and intended outcomes of this project.\n",
        "    \\\\Scope of Work & Risk Identification: Define the parameters and boundaries of the project including risk identification pertinent to these elements.\n",
        "    \\\\Tasks: Outline the main tasks and responsibilities that will be performed during the project.\n",
        "    \\\\Project Deliverables: Describe the expected outcomes and end-products of the project.\n",
        "    \\\\Risk Review Periods: Schedule for regular risk reviews throughout the duration of the project.\n",
        "    \\\\Project Timeline: State the start, end, and key milestones dates.\n",
        "    \\\\Payment Schedule: Outline the payment terms, milestones linked to payments.\n",
        "    \\\\Risk Management: Describe your approach to risk management and how potential risks will be forecasted, addressed, and mitigated during the project.\n",
        "    \\\\Terms and Conditions: Point out any legal agreements related to the project.\n",
        "    \\\\Acceptance: Define what defines successful deliverables and outcome of the project.\n",
        "    \\\\ Communication Plan: Explain the communication strategy for stakeholders involved in the project.\n",
        "    \\\\ For each section, please provide an example text that is representative of content that would typically be included in a real-world project initiation document for the specified topic.\n",
        "    \\\\ The example text should be relevant and realistic, serving as a robust template for each category where applicable. The overall document should not exceed or summarize in 2500 words.\n",
        "    \\\\ The final output should be a detailed and structured document that can serve as a solid example for initiating a project related to {topic}.\"\"\"\n",
        ")\n",
        "script_template = PromptTemplate(\n",
        "    input_variables= ['title'],\n",
        "    template=  \"\"\" Please generate a comprehensive Project Initiation Document text on this TITLE :{topic} using Azure Framework include images\"\"\"\n",
        ")\n",
        "\n",
        "# memory\n",
        "# using to store the memory of the conversation\n",
        "memory = ConversationBufferMemory(input_key='topic', memory_key='chat_history')\n",
        "\n",
        "# Memory and LLM setup\n",
        "llm = openai.OpenAI(temperature= 0)\n",
        "title_chain = LLMChain(llm=llm, prompt=title_template, verbose=True, output_key= 'title', memory=memory)\n",
        "script_chain = LLMChain(llm=llm, prompt=script_template, verbose=True, output_key='script', memory=memory)\n",
        "sequential_chain = SequentialChain(chains=[title_chain,script_chain], input_variables=['topic'], output_variables=['title', 'script'], verbose=True)\n",
        "\n",
        "# Run chains if prompt is given\n",
        "if prompt:\n",
        "    # Get the response from the chains\n",
        "    response = sequential_chain({'topic': prompt})\n",
        "\n",
        "    # Display the response in the app\n",
        "    st.write(response['title'])\n",
        "    st.write(response['script'])\n",
        "\n",
        "    # Allow user to download the response as a Word document\n",
        "    combined_text = f\"{response['title']}\\n\\n{response['script']}\"\n",
        "    word_file = save_to_word(\"Project Document\", combined_text)\n",
        "    st.download_button(label='ðŸ“ Download Word Document',\n",
        "                       data=word_file,\n",
        "                       file_name='project_document.docx',\n",
        "                       mime='application/vnd.openxmlformats-officedocument.wordprocessingml.document')\n",
        "\n",
        "    # Expandable section for message history\n",
        "    with st.expander('Message History'):\n",
        "        st.info(memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQzQC21sGzgj",
        "outputId": "0dc5b5dc-021f-4dd2-f962-80f67d1fb49a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltMNTIvpHCV5",
        "outputId": "52b36f8a-bb5c-46b5-9448-15e78221d8f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors and audited 22 packages in 2.822s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 1 \u001b[93mmoderate\u001b[0m severity vulnerability\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n",
            "\u001b[K\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "PNueWZeMHHqc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1zeeC1iHLVE",
        "outputId": "3fbed981-5000-4b5a-e619-b9b0b100583a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.171.86.225\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.105s\n",
            "your url is: https://polite-shirts-guess.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "80pQPLj7HNuh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}